#!/usr/bin/env python3
"""
author: Gongshan He
description: Command-line based File Statistics Tool (file-stats)
"""
##################################################################
#                         Version Check                          #
##################################################################
import sys

# check the version of python
if sys.version_info < (3, 5):
    print('Error: Python 3.5 or higher is required.')
    sys.exit(1)

import argparse
import concurrent.futures
import csv
import json
import math
import os
import re
import fnmatch
import shutil
import stat
from datetime import datetime
from enum import Enum
from time import time
from typing import Dict, Tuple, List, Set
from collections import defaultdict, OrderedDict
from functools import cmp_to_key

##################################################################
#                            Constant                            #
##################################################################
PROJECT_NAME = 'file-stats'
PROJECT_VERSION = '1.0'
PROJECT_URL = f'github.com/hegongshan/{PROJECT_NAME} v{PROJECT_VERSION}'
PROJECT_DESCRIPTION = f'{PROJECT_NAME} - Command-line based File Statistics Tool'

PATTERN = ', *'
SEPARATOR = '-'
UNKNOWN = 'unknown'


##################################################################
#                           Enum Class                           #
##################################################################
class Platform(Enum):
    MACOS = 'darwin'
    LINUX = 'linux'
    WINDOWS = 'win32'


class FileInfo(Enum):
    # basic attributes
    TYPE = 'type'
    PERM = 'perm'
    SIZE = 'size'
    NUM_LINK = 'nlink'
    UID = 'uid'
    GID = 'gid'
    CHANGE_TIME = 'ctime'
    MODIFICATION_TIME = 'mtime'
    BIRTH_TIME = 'btime'

    # extended attributes
    EXTENSION = 'ext'
    NUM_FILE = 'nfile'
    NUM_LINE = 'nline'
    NUM_HIDDEN_FILE = 'nhidden'
    NUM_BLOCK = 'nblock'
    ARCHIVE = 'archive'
    COMPRESSED = 'compress'
    ENCRYPTED = 'encrypted'
    READONLY = 'readonly'
    APPENDONLY = 'appendonly'
    EXECUTABLE = 'executable'


class FileType(Enum):
    FILE = 'file'
    DIR = 'dir'
    SYMLINK = 'symlink'
    CHARACTER = 'character'
    BLOCK = 'block'
    PIPE = 'pipe'
    SOCKET = 'socket'
    DOOR = 'door'
    PORT = 'port'
    WHITEOUT = 'whiteout'
    UNKNOWN = 'unknown'


class BaseUnit(Enum):
    """
    Reference link: https://en.wikipedia.org/wiki/Byte#Multiple-byte_units
    """
    IEC = 1024  # International Electrotechnical Commission
    SI = 1000  # International System of Units


class SizeUnit(Enum):
    B = 'B'

    # IEC
    KIB = 'KiB'
    MIB = 'MiB'
    GIB = 'GiB'
    TIB = 'TiB'
    PIB = 'PiB'

    # SI
    KB = 'KB'
    MB = 'MB'
    GB = 'GB'
    TB = 'TB'
    PB = 'PB'

    # best suitable unit
    AUTO = 'auto'

    # without unit
    RAW = 'raw'


class SizeStats(Enum):
    MIN = 'min'
    MAX = 'max'
    AVG = 'avg'
    MEDIAN = 'median'
    RANGE = 'range'
    MODE = 'mode'
    VARIANCE = 'variance'
    STDDEV = 'stddev'
    P90 = 'p90'
    P95 = 'p95'
    P99 = 'p99'
    TOTAL_SIZE = 'total_size'
    NUM_FILE = 'number_of_files'


class PlotType(Enum):
    BAR = 'bar'
    PIE = 'pie'
    CDF = 'cdf'  # Cumulative Distribution Function


##################################################################
#                         Utility Class                          #
##################################################################
class FileUtil(object):

    @staticmethod
    def get_file_type(mode: int) -> str:
        if stat.S_ISDIR(mode):
            return FileType.DIR.value

        if stat.S_ISREG(mode):
            return FileType.FILE.value

        if stat.S_ISLNK(mode):
            return FileType.SYMLINK.value

        if stat.S_ISCHR(mode):
            return FileType.CHARACTER.value

        if stat.S_ISBLK(mode):
            return FileType.BLOCK.value

        if stat.S_ISSOCK(mode):
            return FileType.SOCKET.value

        if stat.S_ISFIFO(mode):
            return FileType.PIPE.value

        if hasattr(stat, 'S_ISDOOR') and stat.S_ISDOOR(mode):
            return FileType.DOOR.value

        if hasattr(stat, 'S_ISPORT') and stat.S_ISPORT(mode):
            return FileType.PORT.value

        if hasattr(stat, 'S_ISWHT') and stat.S_ISWHT(mode):
            return FileType.WHITEOUT.value

        return FileType.UNKNOWN.value

    @staticmethod
    def calculate_file_lines(pathname: str) -> int:
        # large file: > 100 MiB, read it line by line
        # other file: <= 100 MiB, read all lines at a time
        is_large_file = os.path.getsize(pathname) > 100 * 1024 * 1024
        try:
            count = 0
            with open(pathname, 'r') as file:
                if is_large_file:
                    for _ in file:
                        count += 1
                else:
                    count += len(file.readlines())
        except UnicodeDecodeError:
            count = 0
            with open(pathname, 'rb') as file:
                if is_large_file:
                    for _ in file:
                        count += 1
                else:
                    count += len(file.readlines())
        return count

    @staticmethod
    def is_hidden(pathname: str) -> bool:
        if not pathname or not os.path.exists(pathname):
            return False

        stat_result = os.lstat(pathname)
        if sys.platform == Platform.WINDOWS.value:
            return bool(stat_result.st_file_attributes & stat.FILE_ATTRIBUTE_HIDDEN)

        if (sys.platform == Platform.MACOS.value
                and bool(stat_result.st_flags & stat.UF_HIDDEN)):
            return True

        # Linux + macOS
        filename = os.path.basename(pathname)
        return filename[0] == '.'

    @staticmethod
    def is_archive(pathname: str) -> bool:
        if not pathname or not os.path.exists(pathname):
            return False

        stat_result = os.lstat(pathname)
        if sys.platform == Platform.WINDOWS.value:
            return bool(stat_result.st_file_attributes & stat.FILE_ATTRIBUTE_ARCHIVE)

        if (sys.platform == Platform.MACOS.value
                and bool(stat_result.st_flags & stat.SF_ARCHIVED)):
            return True

        # Linux + macOS
        filename = os.path.basename(pathname)
        dot_index = filename.find('.')
        if dot_index == -1:
            return False

        ext = filename[dot_index:].lower()
        return ext == '.tar' or ext.startswith('.tar.')

    @staticmethod
    def is_compressed(pathname: str) -> bool:
        if not pathname or not os.path.exists(pathname):
            return False

        stat_result = os.lstat(pathname)
        if (sys.platform == Platform.WINDOWS.value
                and bool(stat_result.st_file_attributes & stat.FILE_ATTRIBUTE_COMPRESSED)):
            return True

        if (sys.platform == Platform.MACOS.value
                and bool(stat_result.st_flags & stat.UF_COMPRESSED)):
            return True

        ext = os.path.splitext(pathname)[1]
        if not ext:
            return False

        ext = ext.lower()
        return ext in {'.rar', '.zip', '.7z', '.gz', '.tgz',
                       '.bz2', '.tbz2', '.xz', '.txz'}

    @staticmethod
    def is_encrypted(pathname: str) -> bool:
        if not pathname or not os.path.exists(pathname):
            return False

        stat_result = os.lstat(pathname)
        if sys.platform == Platform.WINDOWS.value:
            return bool(stat_result.st_file_attributes & stat.FILE_ATTRIBUTE_ENCRYPTED)

        return False

    @staticmethod
    def is_readonly(pathname: str) -> bool:
        if not pathname or not os.path.exists(pathname):
            return False

        stat_result = os.lstat(pathname)
        if sys.platform == Platform.WINDOWS.value:
            return bool(stat_result.st_file_attributes & stat.FILE_ATTRIBUTE_READONLY)

        if (sys.platform == Platform.MACOS.value
                and bool(stat_result.st_flags & stat.UF_IMMUTABLE)):
            return True

        # Linux + macOS
        has_read_permission = bool(stat_result.st_mode & stat.S_IRUSR)
        has_write_permission = bool(stat_result.st_mode & stat.S_IWUSR)
        return has_read_permission and not has_write_permission

    @staticmethod
    def is_appendonly(pathname: str) -> bool:
        if not pathname or not os.path.exists(pathname):
            return False

        stat_result = os.lstat(pathname)
        if sys.platform == Platform.MACOS.value:
            return bool(stat_result.st_flags & stat.UF_APPEND)

        return False

    @staticmethod
    def is_executable(pathname: str) -> bool:
        if not pathname or not os.path.exists(pathname):
            return False

        stat_result = os.lstat(pathname)
        return bool(stat_result.st_mode & stat.S_IXUSR)

    @staticmethod
    def get_size_base(unit: SizeUnit) -> int:
        if unit in {SizeUnit.RAW, SizeUnit.B, SizeUnit.KIB, SizeUnit.MIB,
                    SizeUnit.GIB, SizeUnit.TIB, SizeUnit.PIB, SizeUnit.AUTO}:
            return BaseUnit.IEC.value

        return BaseUnit.SI.value

    @staticmethod
    def get_best_exp_and_unit(size: float, base: int) -> Tuple[int, SizeUnit]:
        assert size >= 0

        std_sizes = [base, base ** 2, base ** 3, base ** 4, base ** 5]
        if 0 <= size < std_sizes[0]:
            return 0, SizeUnit.B
        if std_sizes[0] <= size < std_sizes[1]:
            return 1, SizeUnit.KIB if base == BaseUnit.IEC.value else SizeUnit.KB
        if std_sizes[1] <= size < std_sizes[2]:
            return 2, SizeUnit.MIB if base == BaseUnit.IEC.value else SizeUnit.MB
        if std_sizes[2] <= size < std_sizes[3]:
            return 3, SizeUnit.GIB if base == BaseUnit.IEC.value else SizeUnit.GB
        if std_sizes[3] <= size < std_sizes[4]:
            return 4, SizeUnit.TIB if base == BaseUnit.IEC.value else SizeUnit.TB
        return 5, SizeUnit.PIB if base == BaseUnit.IEC.value else SizeUnit.PB

    @staticmethod
    def get_size_exp(unit: SizeUnit) -> int:
        if unit == SizeUnit.B or unit == SizeUnit.RAW:
            return 0
        if unit == SizeUnit.KIB or unit == SizeUnit.KB:
            return 1
        if unit == SizeUnit.MIB or unit == SizeUnit.MB:
            return 2
        if unit == SizeUnit.GIB or unit == SizeUnit.GB:
            return 3
        if unit == SizeUnit.TIB or unit == SizeUnit.TB:
            return 4
        return 5

    @staticmethod
    def get_size_desc(size: float, unit: SizeUnit = SizeUnit.AUTO) -> str:
        base = FileUtil.get_size_base(unit)

        if unit == SizeUnit.AUTO:
            exp, unit = FileUtil.get_best_exp_and_unit(size, BaseUnit.IEC.value)
        else:
            exp = FileUtil.get_size_exp(unit)

        new_size = size / (base ** exp)
        precision = '.0f' if GenericUtil.is_integer(new_size) else '.3f'

        if unit == SizeUnit.RAW:
            return f'{new_size:{precision}}'
        return f'{new_size:{precision}} {unit.value}'


class GenericUtil(object):

    @staticmethod
    def flatten_dict(data: Dict) -> List:
        flatten_list = []
        for k, v in data.items():
            if isinstance(v, dict):
                sublist = GenericUtil.flatten_dict(v)
                for item in sublist:
                    flatten_list.append([k] + item)
            else:
                flatten_list.append([k, v])
        return flatten_list

    @staticmethod
    def flatten_nfile_dict(data: Dict) -> List:
        flatten_list = []
        for path, nfile in data.items():
            flatten_list.append([path] + [num for ft, num in nfile.items()])
        return flatten_list

    @staticmethod
    def print_error(message: str) -> None:
        print(f'\033[91m{message}\033[0m')

    @staticmethod
    def is_integer(value: float) -> bool:
        return value % 1 == 0


class PlotUtil(object):
    @staticmethod
    def calculate_cdf(x, total, data):
        count = 0
        for item in data:
            if item[-2] <= x[-2]:
                count += item[-1]
        return count / total

    @staticmethod
    def plot(data, plot_name=None, plot_type=PlotType.BAR.value):
        try:
            import matplotlib.pyplot as plt
            import numpy as np
        except ImportError:
            GenericUtil.print_error('pip install matplotlib')
            exit(1)

        if plot_type == PlotType.CDF.value:
            sorted_data = sorted(data, key=lambda item: item[-2])

            total = sum([item[-1] for item in sorted_data])
            cdf_values = [PlotUtil.calculate_cdf(item, total, sorted_data) for item in sorted_data]

            half_x = 0
            for idx, val in enumerate(cdf_values):
                if val >= 0.5:
                    half_x = idx
                    break
            plt.hlines(0.5, xmin=0, xmax=half_x, colors='gray', linestyles='dashed')
            plt.vlines(half_x, ymin=0, ymax=0.5, colors='gray', linestyles='dashed')

            plt.plot(cdf_values)
        else:
            x = ['_'.join(map(str, item[:-1])) for item in data]
            y = [item[-1] for item in data]

            if plot_type == PlotType.BAR.value:
                plt.bar(x, y)
                for x_idx, y_val in enumerate(y):
                    plt.text(x_idx, y_val + 2, y_val, ha='center')
                plt.xticks(rotation=-45)
            else:
                assert plot_type == PlotType.PIE.value
                plt.pie(y, labels=x, autopct='%1.1f%%', startangle=140, labeldistance=1.1)

        if plot_name:
            plt.savefig(plot_name)
        else:
            plt.show()


class OrderedSet(set):
    def __init__(self, iterable):
        super().__init__()
        self.data = OrderedDict()
        for item in iterable:
            if item in self.data:
                continue
            self.data[item] = None

    def __contains__(self, item):
        return item in self.data

    def __iter__(self):
        return iter(self.data)

    def __len__(self):
        return len(self.data)

    def __repr__(self):
        converted_data = map(lambda item: f"'{item}'", self.data.keys())
        return '{' + ', '.join(converted_data) + '}'


##################################################################
#                           Core Class                           #
##################################################################
class FileStats(object):

    def __init__(self,
                 rootdir: str,
                 stats_type_set: Set[str],
                 exclude_dirs: List[str] = None,
                 exclude_files: List[str] = None,
                 exclude_exts: List[str] = None,
                 exclude_pattern: str = None,
                 detail: bool = False,
                 use_name: bool = False,
                 use_symbol: bool = False,
                 verbose: bool = False,
                 ignore_hidden_file: bool = False,
                 jobs: int = 1):
        self._rootdir = rootdir
        self._stats_set = stats_type_set

        self._exclude_dirs = exclude_dirs
        self._exclude_files = exclude_files
        self._exclude_exts = exclude_exts
        self._exclude_patten = exclude_pattern

        self._detail = detail
        self._use_name = use_name
        self._use_symbol = use_symbol
        self._verbose = verbose
        self._ignore_hidden_file = ignore_hidden_file
        self._jobs = jobs

        self._data_dict = defaultdict(dict)

        self._start_time = time()
        self._count(self._rootdir)
        self._end_time = time()

    @property
    def time(self) -> float:
        return self._end_time - self._start_time

    @property
    def data(self) -> Dict:
        return self._data_dict

    @property
    def stats_type_set(self) -> Set[str]:
        return self._stats_set

    def _count(self, dirname):
        if self._jobs == 1:
            self._count_internal(dirname)
        else:
            subdir = self._count_internal(dirname, recursive=False)
            with concurrent.futures.ThreadPoolExecutor() as executor:
                executor.map(self._count_internal, subdir)

    def _count_internal(self, dirname, recursive=True) -> List:
        if self._verbose:
            print(f'dir {dirname}')

        subdir = []
        for filename in os.listdir(dirname):
            pathname = os.path.join(dirname, filename)

            file_stat = os.lstat(pathname)
            file_type = FileUtil.get_file_type(file_stat.st_mode)
            is_dir = file_type == FileType.DIR.value

            if self._verbose:
                print(f'{file_type}: {pathname}')

            if self._ignore_hidden_file and FileUtil.is_hidden(pathname):
                continue

            if self._exclude_dirs and is_dir and filename in self._exclude_dirs:
                if self._verbose:
                    print(f'exclude {pathname}')
                continue

            if self._exclude_files and not is_dir and filename in self._exclude_files:
                if self._verbose:
                    print(f'exclude {pathname}')
                continue

            if self._exclude_exts and not is_dir and os.path.splitext(filename)[1] in self._exclude_exts:
                if self._verbose:
                    print(f'exclude {pathname}')
                continue

            if self._exclude_patten and fnmatch.fnmatch(filename, self._exclude_patten):
                continue

            if FileInfo.TYPE.value in self._stats_set:
                if self._detail:
                    self._data_dict[FileInfo.TYPE.value][pathname] = file_type
                else:
                    self._data_dict[FileInfo.TYPE.value].setdefault(file_type, 0)
                    self._data_dict[FileInfo.TYPE.value][file_type] += 1

            if FileInfo.PERM.value in self._stats_set:
                if self._use_symbol:
                    perm = stat.filemode(file_stat.st_mode)[1:]
                else:
                    perm = oct(file_stat.st_mode)[-3:]

                if self._detail:
                    self._data_dict[FileInfo.PERM.value][pathname] = perm
                else:
                    self._data_dict[FileInfo.PERM.value].setdefault(file_type, {})
                    self._data_dict[FileInfo.PERM.value][file_type].setdefault(perm, 0)
                    self._data_dict[FileInfo.PERM.value][file_type][perm] += 1

            if FileInfo.SIZE.value in self._stats_set and not is_dir:
                size = file_stat.st_size
                if self._detail:
                    self._data_dict[FileInfo.SIZE.value][pathname] = size
                else:
                    self._data_dict[FileInfo.SIZE.value].setdefault(size, 0)
                    self._data_dict[FileInfo.SIZE.value][size] += 1

            if FileInfo.NUM_LINK.value in self._stats_set:
                nlink = file_stat.st_nlink
                if self._detail:
                    self._data_dict[FileInfo.NUM_LINK.value][pathname] = nlink
                else:
                    self._data_dict[FileInfo.NUM_LINK.value].setdefault(file_type, {})
                    self._data_dict[FileInfo.NUM_LINK.value][file_type].setdefault(nlink, 0)
                    self._data_dict[FileInfo.NUM_LINK.value][file_type][nlink] += 1

            if FileInfo.UID.value in self._stats_set:
                uid = file_stat.st_uid
                if self._use_name:
                    import pwd
                    uid = pwd.getpwuid(uid).pw_name

                if self._detail:
                    self._data_dict[FileInfo.UID.value][pathname] = uid
                else:
                    self._data_dict[FileInfo.UID.value].setdefault(uid, 0)
                    self._data_dict[FileInfo.UID.value][uid] += 1

            if FileInfo.GID.value in self._stats_set:
                gid = file_stat.st_gid
                if self._use_name:
                    import grp
                    gid = grp.getgrgid(gid).gr_name

                if self._detail:
                    self._data_dict[FileInfo.GID.value][pathname] = gid
                else:
                    self._data_dict[FileInfo.GID.value].setdefault(gid, 0)
                    self._data_dict[FileInfo.GID.value][gid] += 1

            fmt = '%Y-%m-%d %H:%M:%S' if self._detail else '%Y-%m-%d'
            if FileInfo.CHANGE_TIME.value in self._stats_set:
                ctime = file_stat.st_ctime
                date = datetime.fromtimestamp(ctime).strftime(fmt)
                if self._detail:
                    self._data_dict[FileInfo.CHANGE_TIME.value][pathname] = date
                else:
                    self._data_dict[FileInfo.CHANGE_TIME.value].setdefault(date, 0)
                    self._data_dict[FileInfo.CHANGE_TIME.value][date] += 1

            if FileInfo.MODIFICATION_TIME.value in self._stats_set:
                mtime = file_stat.st_mtime
                date = datetime.fromtimestamp(mtime).strftime(fmt)
                if self._detail:
                    self._data_dict[FileInfo.MODIFICATION_TIME.value][pathname] = date
                else:
                    self._data_dict[FileInfo.MODIFICATION_TIME.value].setdefault(date, 0)
                    self._data_dict[FileInfo.MODIFICATION_TIME.value][date] += 1

            if FileInfo.BIRTH_TIME.value in self._stats_set:
                btime = file_stat.st_birthtime
                date = datetime.fromtimestamp(btime).strftime(fmt)
                if self._detail:
                    self._data_dict[FileInfo.BIRTH_TIME.value][pathname] = date
                else:
                    self._data_dict[FileInfo.BIRTH_TIME.value].setdefault(date, 0)
                    self._data_dict[FileInfo.BIRTH_TIME.value][date] += 1

            if (FileInfo.EXTENSION.value in self._stats_set
                    and file_type == FileType.FILE.value):
                ext = os.path.splitext(filename)[1]
                ext = ext if ext else UNKNOWN
                if self._detail:
                    self._data_dict[FileInfo.EXTENSION.value][pathname] = ext
                else:
                    self._data_dict[FileInfo.EXTENSION.value].setdefault(ext, 0)
                    self._data_dict[FileInfo.EXTENSION.value][ext] += 1

            if FileInfo.NUM_FILE.value in self._stats_set:
                self._data_dict[FileInfo.NUM_FILE.value].setdefault(dirname, {})
                for ft in FileType:
                    self._data_dict[FileInfo.NUM_FILE.value][dirname].setdefault(ft.value, 0)
                self._data_dict[FileInfo.NUM_FILE.value][dirname][file_type] += 1

            if (FileInfo.NUM_LINE.value in self._stats_set
                    and file_type == FileType.FILE.value):
                self._data_dict[FileInfo.NUM_LINE.value].setdefault(pathname, {})
                self._data_dict[FileInfo.NUM_LINE.value][pathname] = FileUtil.calculate_file_lines(pathname)

            if (FileInfo.NUM_HIDDEN_FILE.value in self._stats_set
                    and FileUtil.is_hidden(pathname)):
                self._data_dict[FileInfo.NUM_HIDDEN_FILE.value].setdefault(dirname, 0)
                self._data_dict[FileInfo.NUM_HIDDEN_FILE.value][dirname] += 1

            if FileInfo.NUM_BLOCK.value in self._stats_set:
                self._data_dict[FileInfo.NUM_BLOCK.value][pathname] = file_stat.st_blocks

            if (FileInfo.ARCHIVE.value in self._stats_set
                    and FileUtil.is_archive(pathname)):
                self._data_dict[FileInfo.ARCHIVE.value].setdefault(dirname, 0)
                self._data_dict[FileInfo.ARCHIVE.value][dirname] += 1

            if (FileInfo.COMPRESSED.value in self._stats_set
                    and FileUtil.is_compressed(pathname)):
                self._data_dict[FileInfo.COMPRESSED.value].setdefault(dirname, 0)
                self._data_dict[FileInfo.COMPRESSED.value][dirname] += 1

            if (FileInfo.ENCRYPTED.value in self._data_dict
                    and FileUtil.is_encrypted(pathname)):
                self._data_dict[FileInfo.ENCRYPTED.value].setdefault(dirname, 0)
                self._data_dict[FileInfo.ENCRYPTED.value][dirname] += 1

            if (FileInfo.READONLY.value in self._stats_set
                    and FileUtil.is_readonly(pathname)):
                self._data_dict[FileInfo.READONLY.value].setdefault(dirname, 0)
                self._data_dict[FileInfo.READONLY.value][dirname] += 1

            if FileInfo.APPENDONLY.value in self._stats_set and FileUtil.is_appendonly(pathname):
                self._data_dict[FileInfo.APPENDONLY.value].setdefault(dirname, 0)
                self._data_dict[FileInfo.APPENDONLY.value][dirname] += 1

            if (FileInfo.EXECUTABLE.value in self._stats_set
                    and not is_dir
                    and FileUtil.is_executable(pathname)):
                self._data_dict[FileInfo.EXECUTABLE.value].setdefault(dirname, 0)
                self._data_dict[FileInfo.EXECUTABLE.value][dirname] += 1

            if is_dir and recursive:
                self._count(pathname)
            else:
                subdir.append(pathname)

        return subdir

    def header(self, stats_type: str):
        if stats_type == FileInfo.SIZE.value:
            if self._detail:
                return ['File Name', 'File Size']
            return ['File Size', 'Number of Files']

        if stats_type == FileInfo.TYPE.value:
            if self._detail:
                return ['File Name', 'File Type']
            return ['File Type', 'Number of Files']

        if stats_type == FileInfo.PERM.value:
            if self._detail:
                return ['File Name', 'File Permission']
            return ['File Type', 'Permission', 'Number of Files']

        if stats_type == FileInfo.NUM_LINK.value:
            if self._detail:
                return ['File Name', 'Number of Links']
            return ['File Type', 'Number of Links', 'Number of Files']

        if stats_type == FileInfo.UID.value:
            if self._use_name:
                return ['User Name', 'Number of Files']
            return ['User ID', 'Number of Files']

        if stats_type == FileInfo.GID.value:
            if self._use_name:
                return ['Group Name', 'Number of Files']
            return ['Group ID', 'Number of Files']

        if stats_type == FileInfo.CHANGE_TIME.value:
            if self._detail:
                return ['File Name', 'Change Time']
            return ['Change Time', 'Number of Files']

        if stats_type == FileInfo.MODIFICATION_TIME.value:
            if self._detail:
                return ['File Name', 'Modification Time']
            return ['Modification Time', 'Number of Files']

        if stats_type == FileInfo.BIRTH_TIME.value:
            if self._detail:
                return ['File Name', 'Birth Time']
            return ['Birth Time', 'Number of Files']

        if stats_type == FileInfo.EXTENSION.value:
            if self._detail:
                return ['File Name', 'Extension']
            return ['Extension', 'Number of Files']

        if stats_type == FileInfo.NUM_FILE.value:
            return ['Dir Name'] + [ft.value for ft in FileType]

        if stats_type == FileInfo.NUM_LINE.value:
            return ['File Name', 'Number of Lines']

        if stats_type == FileInfo.NUM_HIDDEN_FILE.value:
            return ['Dir Name', 'Number of Hidden Files']

        if stats_type == FileInfo.NUM_BLOCK.value:
            return ['Pathname', 'Number of Blocks']

        if stats_type == FileInfo.ARCHIVE.value:
            return ['Dir Name', 'Number of Archive Files']

        if stats_type == FileInfo.COMPRESSED.value:
            return ['Dir Name', 'Number of Compressed Files']

        if stats_type == FileInfo.ENCRYPTED.value:
            return ['Dir Name', 'Number of Encrypted Files']

        if stats_type == FileInfo.READONLY.value:
            return ['Dir Name', 'Number of Readonly Files']

        if stats_type == FileInfo.APPENDONLY.value:
            return ['Dir Name', 'Number of Append-only Files']

        assert stats_type == FileInfo.EXECUTABLE.value
        return ['Dir Name', 'Number of Executable Files']


def parse_args():
    parser = argparse.ArgumentParser(description=PROJECT_DESCRIPTION)

    # General options
    parser.add_argument('-r',
                        '--rootdir',
                        type=str,
                        required=True,
                        help='Root directory')
    parser.add_argument('-s',
                        '--stats',
                        nargs='+',
                        choices=[stat_type.value for stat_type in FileInfo],
                        default='type',
                        help='Stats type')
    parser.add_argument('-j',
                        '--jobs',
                        nargs='?',
                        const=os.cpu_count(),
                        default=1,
                        type=int,
                        help='Specify the number of jobs to run simultaneously')
    parser.add_argument('-i',
                        '--ignore-hidden-file',
                        action='store_true',
                        default=False,
                        help='Ignore hidden files')
    parser.add_argument('--detail',
                        action='store_true',
                        help='Show detail')

    # Mode options
    parser.add_argument('-v',
                        '--verbose',
                        action='store_true',
                        help='Verbose mode')
    parser.add_argument('-q',
                        '--quiet',
                        action='store_true',
                        help='Quiet mode')

    # Exclude options
    parser.add_argument('--exclude-dirs',
                        type=str,
                        help='Exclude dirs')
    parser.add_argument('--exclude-files',
                        type=str,
                        help='Exclude files')
    parser.add_argument('--exclude-exts',
                        type=str,
                        help='Exclude file name extensions')
    parser.add_argument('--exclude-pattern',
                        type=str,
                        help='UNIX shell pattern')

    # Size options
    size_group = parser.add_mutually_exclusive_group()
    size_group.add_argument('--raw',
                            action='store_true',
                            help='Do not show B unit suffix')
    size_group.add_argument('-H', '--human-readable',
                            action='store_true',
                            help='Human-readable output. ')
    size_group.add_argument('-k',
                            action='store_true',
                            help='Use KiB, or KB with --si')
    size_group.add_argument('-m',
                            action='store_true',
                            help='Use MiB, or MB with --si')
    size_group.add_argument('-g',
                            action='store_true',
                            help='Use GiB, or GB with --si')
    size_group.add_argument('-t',
                            action='store_true',
                            help='Use TiB, or TB with --si')
    size_group.add_argument('-p',
                            action='store_true',
                            help='Use PiB, or PB with --si')
    parser.add_argument('--si',
                        action='store_true',
                        help='Use international system of units (SI)')
    parser.add_argument('--size-range',
                        action='store_true',
                        help='Show size range')

    # uid/gid options
    parser.add_argument('-n',
                        '--name',
                        action='store_true',
                        help='Show user name or group name')

    # permission options
    parser.add_argument('--symbol',
                        action='store_true',
                        help='Show symbolic permission')

    # nfile options
    parser.add_argument('-f',
                        '--full-path',
                        action='store_true',
                        default=False,
                        help='Print the full path for each file')

    # Export options
    parser.add_argument('-o',
                        '--output',
                        type=str,
                        help='Output file')

    export_group = parser.add_mutually_exclusive_group()
    export_group.add_argument('-J',
                              '--json',
                              action='store_true',
                              help='Export the results in JSON format.')
    export_group.add_argument('-C',
                              '--csv',
                              action='store_true',
                              help='Export the results in CSV format.')
    export_group.add_argument('--plot-type',
                              type=str,
                              choices=[p.value for p in PlotType],
                              help='Specify the type of the figure')
    return parser.parse_args()


def get_table(headers, datas):
    # construct columns
    columns = [[header] for header in headers]
    for row in datas:
        for col, entry in enumerate(row):
            columns[col].append(entry)

    # calculate the width of each column
    column_widths = []
    for column in columns:
        column_width = max(map(lambda x: len(str(x)), column))
        column_widths.append(column_width + 3)

    # calculate the length of the separator line
    line_length = sum(column_widths) + len(column_widths) - 1
    terminal_width = shutil.get_terminal_size().columns
    separator_line = SEPARATOR * min(line_length, terminal_width)

    # Tabular header
    output_results = [separator_line]
    tabular_header = ''
    for i in range(len(headers)):
        if i == 0:
            tabular_header += f'{headers[i]:<{column_widths[i]}}'
        else:
            tabular_header += f' {headers[i]:>{column_widths[i]}}'
    output_results.append(tabular_header)
    output_results.append(separator_line)

    # Tabular data
    for rows in datas:
        row = ''
        for idx, item in enumerate(rows):
            if idx == 0:
                row += f'{item:<{column_widths[idx]}}'
            else:
                row += f' {item:>{column_widths[idx]}}'
        output_results.append(row)
    output_results.append(separator_line)

    return output_results


def compare_entry(a, b):
    # asc
    if a[0] < b[0]:
        return -1
    if a[0] > b[0]:
        return 1

    # desc
    if a[-1] < b[-1]:
        return 1
    if a[-1] > b[-1]:
        return -1

    for i in range(1, len(a) - 1):
        # asc
        if a[i] < b[i]:
            return -1
        if a[i] > b[i]:
            return 1

    return 0


def count_size_range(size_count_dict: Dict,
                     unit: SizeUnit = SizeUnit.B):
    base = FileUtil.get_size_base(unit)
    std_sizes = [base, base ** 2, base ** 3, base ** 4, base ** 5]

    range_count = {}
    for size, count in size_count_dict.items():
        for idx, std_size in enumerate(std_sizes):
            if size <= std_size or idx == len(std_sizes) - 1:
                std_size_desc = FileUtil.get_size_desc(std_size, unit=unit)
                key = f'≤ {std_size_desc}' if size <= std_size else f'> {std_size_desc}'
                range_count.setdefault(key, 0)
                range_count[key] += count
                break
    return range_count


def get_size_dict(args, file_stats, unit):
    new_size_dict = {}
    if FileInfo.SIZE.value not in file_stats.data:
        return new_size_dict

    data = file_stats.data[FileInfo.SIZE.value]

    if args.detail:
        # pathname, size
        for pathname, size in data.items():
            new_size_dict[pathname] = FileUtil.get_size_desc(size, unit)
    elif args.size_range:
        # size range, number of files
        new_size_dict = count_size_range(data, unit=unit)
    else:
        # size, number of files
        for size, num in data.items():
            size_desc = FileUtil.get_size_desc(size, unit)
            new_size_dict[size_desc] = num

    return new_size_dict


def get_additional_size_stats(stats_data, unit, detail_mode):
    total_size = 0
    total_file = 0
    max_size = 0
    min_size = math.inf
    size_mode, max_num = 0, 0

    if detail_mode:
        size_cnt_dict = defaultdict(int)
        for _, size in stats_data.items():
            size_cnt_dict[size] += 1
        stats_data = size_cnt_dict

    for size, num in stats_data.items():
        total_size += size * num
        total_file += num
        if size > max_size:
            max_size = size
        if size < min_size:
            min_size = size
        if max_num < num:
            max_num = num
            size_mode = size

    size_range = max_size - min_size
    avg_size = total_size / total_file

    tmp_sum = 0
    for size, num in stats_data.items():
        tmp_sum += num * ((size - avg_size) ** 2)
    size_var = 1. / total_file * tmp_sum
    size_stddev = math.sqrt(size_var)

    stats_data_list = sorted(GenericUtil.flatten_dict(stats_data),
                             key=lambda x: x[0])
    median_size, p90_size, p95_size, p99_size = 0, 0, 0, 0
    num_sum = 0
    for size, num in stats_data_list:
        num_sum += num
        percent = num_sum / total_file
        if 0.5 <= percent and median_size == 0:
            median_size = size

        if 0.90 <= percent and p90_size == 0:
            p90_size = size

        if 0.95 <= percent and p95_size == 0:
            p95_size = size

        if 0.99 <= percent and p99_size == 0:
            p99_size = size

    return {
        SizeStats.MIN: FileUtil.get_size_desc(min_size, unit),
        SizeStats.MAX: FileUtil.get_size_desc(max_size, unit),
        SizeStats.AVG: FileUtil.get_size_desc(avg_size, unit),
        SizeStats.MEDIAN: FileUtil.get_size_desc(median_size, unit),
        SizeStats.RANGE: size_range,
        SizeStats.MODE: FileUtil.get_size_desc(size_mode, unit),
        SizeStats.VARIANCE: f'{size_var:.3f}',
        SizeStats.STDDEV: f'{size_stddev:.3f}',
        SizeStats.P90: FileUtil.get_size_desc(p90_size, unit),
        SizeStats.P95: FileUtil.get_size_desc(p95_size, unit),
        SizeStats.P99: FileUtil.get_size_desc(p99_size, unit),
        SizeStats.TOTAL_SIZE: FileUtil.get_size_desc(total_size, unit),
        SizeStats.NUM_FILE: total_file
    }


def export_json(file_stats, output):
    if not output:
        print(json.dumps(file_stats.data, ensure_ascii=True, indent=4))
    else:
        with open(output, 'w+') as file:
            json.dump(file_stats.data, file, ensure_ascii=True, indent=4)


def export_csv(file_stats, output):
    if not output:
        for idx, (stats_type, stats_data) in enumerate(file_stats.data.items()):
            # blank line
            if idx >= 1:
                print()

            print(','.join(file_stats.header(stats_type)))
            if stats_type == FileInfo.NUM_FILE.value:
                flatten_list = GenericUtil.flatten_nfile_dict(stats_data)
            else:
                flatten_list = GenericUtil.flatten_dict(stats_data)
            for entry_list in flatten_list:
                print(','.join(map(str, entry_list)))
    else:
        csv_file_name, csv_ext_name = os.path.splitext(output)
        if not csv_ext_name:
            csv_ext_name = '.csv'
        only_one_entry = len(file_stats.data) == 1
        for stats_type, stats_data in file_stats.data.items():
            if only_one_entry:
                filename = f'{csv_file_name}{csv_ext_name}'
            else:
                filename = f'{csv_file_name}-{stats_type}{csv_ext_name}'

            with open(filename, 'w+') as file:
                csv_writer = csv.writer(file)
                csv_writer.writerow(file_stats.header(stats_type))
                csv_writer.writerows(GenericUtil.flatten_dict(stats_data))


def export_figure(file_stats, plot_type, output):
    if output:
        filename, ext = os.path.splitext(output)
        if not ext:
            ext = '.pdf'
    else:
        filename, ext = '', ''

    only_one_entry = len(file_stats.data) == 1
    for stats_type in file_stats.stats_type_set:
        if stats_type == FileInfo.NUM_FILE:
            continue

        if not output:
            name = None
        elif only_one_entry:
            name = f'{filename}{ext}'
        else:
            name = f'{filename}_{stats_type}{ext}'

        PlotUtil.plot(GenericUtil.flatten_dict(file_stats.data[stats_type]),
                      name,
                      plot_type)


def export_table(file_stats, new_size_dict, unit, quiet, output):
    output_results = []
    if not quiet:
        # elapsed time
        output_results.append(f'{PROJECT_URL}  Time = {file_stats.time:.3f} s')
    for stats_type in file_stats.stats_type_set:
        th = file_stats.header(stats_type=stats_type)
        data = file_stats.data[stats_type]
        if not data:
            continue

        if stats_type == FileInfo.SIZE.value:
            data = new_size_dict

        if stats_type == FileInfo.NUM_FILE.value:
            res = GenericUtil.flatten_nfile_dict(data)
        else:
            res = GenericUtil.flatten_dict(data)
        nested_list = sorted(res,
                             key=cmp_to_key(compare_entry))

        output_results.extend(get_table(th, nested_list))

        # Statistics: Max, Min, Avg, Total, ...
        if stats_type == FileInfo.SIZE.value:
            size_stats = get_additional_size_stats(file_stats.data[FileInfo.SIZE.value], unit, args.detail)
            output_results.append('')
            output_results.append('Additional Size Statistics:')
            size_stats_header = []
            size_stats_data = []
            for size_stats_type in SizeStats:
                size_stats_header.append(size_stats_type.value)
                size_stats_data.append(size_stats[size_stats_type])
            output_results.extend(get_table(size_stats_header, [size_stats_data]))

    out = '\n'.join(output_results)

    # Output
    if not output:
        print(out)
    else:
        with open(output, 'w+') as file:
            file.write(f'{out}\n')


def main():
    args = parse_args()

    if not os.path.exists(args.rootdir):
        GenericUtil.print_error(f'{args.rootdir} does not exist!')
        exit(1)
    if not os.path.isdir(args.rootdir):
        GenericUtil.print_error(f'{args.rootdir} is not a directory!')
        exit(1)
    if args.full_path:
        rootdir = os.path.abspath(args.rootdir)
    else:
        rootdir = args.rootdir

    if isinstance(args.stats, list):
        stats_type_set = OrderedSet(args.stats)
    else:
        stats_type_set = {args.stats}

    if args.name and (FileInfo.UID.value or FileInfo.GID.value) in stats_type_set:
        if sys.platform not in {Platform.MACOS.value, Platform.LINUX.value}:
            GenericUtil.print_error(f'Error: -n/--name option does not support {sys.platform}.')
            exit(1)

    btime_disabled = (FileInfo.BIRTH_TIME.value in stats_type_set
                      and not hasattr(os.stat_result, 'st_birthtime'))
    nblock_disabled = (FileInfo.NUM_BLOCK.value in stats_type_set
                       and not hasattr(os.stat_result, 'st_blocks'))
    if btime_disabled or nblock_disabled:
        if btime_disabled:
            feature = FileInfo.BIRTH_TIME.value
        else:
            feature = FileInfo.NUM_BLOCK.value
        GenericUtil.print_error(
            f'Error: The operating system does not support this feature \'{feature}\'.')
        exit(1)

    jobs = args.jobs if args.jobs else 1

    # exclude dirs, files, and extensions
    exclude_dirs = re.split(PATTERN, args.exclude_dirs) if args.exclude_dirs else None
    exclude_files = re.split(PATTERN, args.exclude_files) if args.exclude_files else None
    exclude_exts = re.split(PATTERN, args.exclude_exts) if args.exclude_exts else None
    exclude_pattern = args.exclude_pattern if args.exclude_pattern else None

    file_stats = FileStats(rootdir,
                           stats_type_set=stats_type_set,
                           exclude_dirs=exclude_dirs,
                           exclude_files=exclude_files,
                           exclude_exts=exclude_exts,
                           exclude_pattern=exclude_pattern,
                           detail=args.detail,
                           use_name=args.name,
                           use_symbol=args.symbol,
                           verbose=args.verbose,
                           jobs=jobs,
                           ignore_hidden_file=args.ignore_hidden_file)

    if args.k:
        unit = SizeUnit.KB if args.si else SizeUnit.KIB
    elif args.m:
        unit = SizeUnit.MB if args.si else SizeUnit.MIB
    elif args.g:
        unit = SizeUnit.GB if args.si else SizeUnit.GIB
    elif args.t:
        unit = SizeUnit.TB if args.si else SizeUnit.TIB
    elif args.p:
        unit = SizeUnit.PB if args.si else SizeUnit.PIB
    elif args.human_readable:
        unit = SizeUnit.AUTO
    elif args.raw:
        unit = SizeUnit.RAW
    else:
        unit = SizeUnit.B

    new_size_dict = get_size_dict(args, file_stats, unit)
    if (args.json or args.csv) and FileInfo.SIZE.value in file_stats.data:
        file_stats.data[FileInfo.SIZE.value] = new_size_dict

    if args.json:
        export_json(file_stats, args.output)
    elif args.csv:
        export_csv(file_stats, args.output)
    elif args.plot_type:
        export_figure(file_stats, args.plot_type, args.output)
    else:
        export_table(file_stats, new_size_dict, unit, args.quiet, args.output)


if __name__ == "__main__":
    main()
